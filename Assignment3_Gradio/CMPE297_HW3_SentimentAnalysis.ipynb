{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CMPE297_HW3_SentimentAnalysis",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "913084ac4d9c48f5910abc1d37e0e4e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_dcf25a1fbdec42b393dfd3c706ae0de4",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_db6df55602e34660b231f6c4545311e6",
              "IPY_MODEL_21a6d1d3436f474393b5d92a2cf6849d",
              "IPY_MODEL_d146e1c3e5ad47eba853fe3937f6ee4d"
            ]
          }
        },
        "dcf25a1fbdec42b393dfd3c706ae0de4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "db6df55602e34660b231f6c4545311e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a61da213948d434890bd7ee1164d0f6e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f74cfe9248494c46b60efc02480fb327"
          }
        },
        "21a6d1d3436f474393b5d92a2cf6849d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f945a55dfb4944db8fc65f6b8246b23d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ea6364afffd040ad8b03f544d8cb172d"
          }
        },
        "d146e1c3e5ad47eba853fe3937f6ee4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ea94d92e58ab4ea6a769121b2dec7b6b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 1.76MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_885c77acbc804f1da8d979eac5278137"
          }
        },
        "a61da213948d434890bd7ee1164d0f6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f74cfe9248494c46b60efc02480fb327": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f945a55dfb4944db8fc65f6b8246b23d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ea6364afffd040ad8b03f544d8cb172d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ea94d92e58ab4ea6a769121b2dec7b6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "885c77acbc804f1da8d979eac5278137": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8b5b05fb01644be19618a9f0a8b9a732": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_2dd84f2cdd4044c48c383266b5f94cf8",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e15f3ee1b878428984c744e13fbba70c",
              "IPY_MODEL_ee20693f6f2e479d8f8629ac3fa9f91b",
              "IPY_MODEL_0ea61762657d48e78bc03d080878d86c"
            ]
          }
        },
        "2dd84f2cdd4044c48c383266b5f94cf8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e15f3ee1b878428984c744e13fbba70c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_fdde4f376cf54e27834be411660ee339",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e7369e716d3f44b384145ef9651981dc"
          }
        },
        "ee20693f6f2e479d8f8629ac3fa9f91b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_84f4244ed40a4467833733f8e11b116d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 433,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7fa1ff7fe5e54f3694e7bde8702b98eb"
          }
        },
        "0ea61762657d48e78bc03d080878d86c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9cb7a283276a401ea0c0ae81974c81e0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433/433 [00:00&lt;00:00, 12.5kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4af5d809ad4e4904aab501577cc046ff"
          }
        },
        "fdde4f376cf54e27834be411660ee339": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e7369e716d3f44b384145ef9651981dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "84f4244ed40a4467833733f8e11b116d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7fa1ff7fe5e54f3694e7bde8702b98eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9cb7a283276a401ea0c0ae81974c81e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4af5d809ad4e4904aab501577cc046ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "367b641da98f47e2b79f186af9a56cf1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_68c1147d196a4e1aa8899bf43fcb096f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_35ef0385b1254005a745fdbb2447d6dd",
              "IPY_MODEL_3ea1d598c5b34a2db818084f25b1f18c",
              "IPY_MODEL_861a0eb9b8104131aa19789d87495d75"
            ]
          }
        },
        "68c1147d196a4e1aa8899bf43fcb096f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "35ef0385b1254005a745fdbb2447d6dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a4d2d6abc3cf4900b2f16fba490460ab",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9da3848c6a6443c3b4fe85e789bab750"
          }
        },
        "3ea1d598c5b34a2db818084f25b1f18c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_1ec5430d630b4900a37ed8f98f4213fa",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9df819fd50df43279a005f56e25ef58b"
          }
        },
        "861a0eb9b8104131aa19789d87495d75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6c23819ebda540b8a17e551a29d0e9d6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 440M/440M [00:08&lt;00:00, 53.5MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1ec0f63e1b304f9290390917b9b7ea3b"
          }
        },
        "a4d2d6abc3cf4900b2f16fba490460ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9da3848c6a6443c3b4fe85e789bab750": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1ec5430d630b4900a37ed8f98f4213fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9df819fd50df43279a005f56e25ef58b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6c23819ebda540b8a17e551a29d0e9d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1ec0f63e1b304f9290390917b9b7ea3b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sqg4y371CM7X"
      },
      "source": [
        "# **Fine-tuning BERT for Sentiment Analysis**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M2D_810Uruqe"
      },
      "source": [
        "# **References**\n",
        "* https://colab.research.google.com/drive/1f32gj5IYIyFipoINiC8P3DvKat-WWLUK#scrollTo=sqg4y371CM7X\n",
        "* https://gradio.app/getting_started\n",
        "\n",
        "**Please Note:**\n",
        "More details on BERT and evolution in NLP in described in the first notebook under this folder.\n",
        "\n",
        "Path: https://colab.research.google.com/drive/1ed2jC3zmUPi9NiiVEaPb6xCM7MGs2JOO#scrollTo=2PbmYNEUv6M7"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IT93d88Pcepn"
      },
      "source": [
        "**Informative References**:\n",
        "\n",
        "- http://jalammar.github.io/illustrated-bert/\n",
        "- https://huggingface.co/transformers/v2.2.0/index.html\n",
        "- http://mccormickml.com/2019/07/22/BERT-fine-tuning/\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "slO_rmYgwmmE"
      },
      "source": [
        "## **Dataset**\n",
        "https://drive.google.com/uc?export=download&id=1wHt8PsMLsfX5yNSqrt2fSTcb8LEiclcf\n",
        "\n",
        "The train data has 2 files, each containing 1700 complaining/non-complaining tweets. Every tweets in the data contains at least a hashtag of an airline.\n",
        "\n",
        "## **Task**\n",
        "\n",
        "Sentiment Classification task for tweets\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "31OW0dhozvli"
      },
      "source": [
        "## **Loading essential Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_lTXsMK3sNYr"
      },
      "source": [
        "import os\n",
        "import re\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tDf5OjQbX-YK"
      },
      "source": [
        "## **Installing TensorBoard**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VUtvoFg1YB_m",
        "outputId": "29e7f3e7-81d9-4960-fded-f1ca8f861cf6"
      },
      "source": [
        "!pip install tensorboard"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.7/dist-packages (2.6.0)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (1.41.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (57.4.0)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (3.17.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (2.23.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (0.12.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (1.8.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (0.37.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (1.0.1)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (1.19.5)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (3.3.4)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (1.35.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py>=0.4->tensorboard) (1.15.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard) (4.7.2)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard) (4.8.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard) (2021.5.30)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (3.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard) (3.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard) (3.7.4.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZPkdWj18YRQX"
      },
      "source": [
        "from torch.utils.tensorboard import SummaryWriter\n",
        "tb = SummaryWriter()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j1_Tpie3tGp3"
      },
      "source": [
        "## **Downloading the Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_tOJXeR9sx57"
      },
      "source": [
        "# Download data\n",
        "import requests\n",
        "request = requests.get(\"https://drive.google.com/uc?export=download&id=1wHt8PsMLsfX5yNSqrt2fSTcb8LEiclcf\")\n",
        "with open(\"data.zip\", \"wb\") as file:\n",
        "    file.write(request.content)\n",
        "\n",
        "# Unzip data\n",
        "import zipfile\n",
        "with zipfile.ZipFile('data.zip') as zip:\n",
        "    zip.extractall('data')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3xRto0SDBf9w"
      },
      "source": [
        "Loading the train data and labelling it. Dropping unimportant columns and only keeping `id`, `tweet` and `label` columns."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XwjmiM2ktA7d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "outputId": "3048575b-7af2-4137-c637-63ad5a50201a"
      },
      "source": [
        " # Load data and set labels\n",
        "data_complaint = pd.read_csv('data/complaint1700.csv')\n",
        "data_complaint['label'] = 0\n",
        "data_non_complaint = pd.read_csv('data/noncomplaint1700.csv')\n",
        "data_non_complaint['label'] = 1\n",
        "\n",
        "# Concatenate complaining and non-complaining data\n",
        "data = pd.concat([data_complaint, data_non_complaint], axis=0).reset_index(drop=True)\n",
        "\n",
        "# Drop 'airline' column\n",
        "data.drop(['airline'], inplace=True, axis=1)\n",
        "\n",
        "# Display 5 random samples\n",
        "data.sample(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>tweet</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>12687</td>\n",
              "      <td>@AmericanAir Can you help me get home to my da...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3258</th>\n",
              "      <td>154544</td>\n",
              "      <td>.@JetBlue What the heck is the last sec change...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>268</th>\n",
              "      <td>11998</td>\n",
              "      <td>@DeltaAssist may have the worse company polici...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>205</th>\n",
              "      <td>73487</td>\n",
              "      <td>@united has the worst domestic #firstclass htt...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10959</td>\n",
              "      <td>@united kinda feel like the $6.99 you charge f...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          id                                              tweet  label\n",
              "99     12687  @AmericanAir Can you help me get home to my da...      0\n",
              "3258  154544  .@JetBlue What the heck is the last sec change...      1\n",
              "268    11998  @DeltaAssist may have the worse company polici...      0\n",
              "205    73487  @united has the worst domestic #firstclass htt...      0\n",
              "1      10959  @united kinda feel like the $6.99 you charge f...      0"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cp-vfxKZvl6M"
      },
      "source": [
        "* Randomly splitting the entire training data into two sets: a train set with 90% of the data and a validation set with 10% of the data. \n",
        "* We will perform hyperparameter tuning using cross-validation on the train set and use the validation set to compare models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X4HKAFTbvMwI"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = data.tweet.values\n",
        "y = data.label.values\n",
        "\n",
        "X_train, X_val, y_train, y_val =\\\n",
        "    train_test_split(X, y, test_size=0.1, random_state=2020)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pErITNxtyNpe"
      },
      "source": [
        "## **Loading Test Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_JWXnfBlwyWC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "outputId": "d0cd650b-87a6-40f3-a19d-49fba15c244d"
      },
      "source": [
        "# Load test data\n",
        "test_data = pd.read_csv('data/test_data.csv')\n",
        "\n",
        "# Keep important columns\n",
        "test_data = test_data[['id', 'tweet']]\n",
        "\n",
        "# Display 5 samples from the test data\n",
        "test_data.sample(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>792</th>\n",
              "      <td>31624</td>\n",
              "      <td>@AmericanAir I recently used your airline serv...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1037</th>\n",
              "      <td>41480</td>\n",
              "      <td>@VirginAmerica never heard back from status ma...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3873</th>\n",
              "      <td>147113</td>\n",
              "      <td>And this is why we don't fly @Delta! I'm sorry...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>833</th>\n",
              "      <td>33323</td>\n",
              "      <td>@AmericanAir Flight 105 LHR to JFK. Paid for u...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>793</th>\n",
              "      <td>31630</td>\n",
              "      <td>@AmericanAir I just had to pay $250 for my sui...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          id                                              tweet\n",
              "792    31624  @AmericanAir I recently used your airline serv...\n",
              "1037   41480  @VirginAmerica never heard back from status ma...\n",
              "3873  147113  And this is why we don't fly @Delta! I'm sorry...\n",
              "833    33323  @AmericanAir Flight 105 LHR to JFK. Paid for u...\n",
              "793    31630  @AmericanAir I just had to pay $250 for my sui..."
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X79dYY3sxDCi"
      },
      "source": [
        "## **Setting up a GPU for training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K7hxtI4l0SUJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f9568f2-ae21-4090-c644-48babc6cb7e9"
      },
      "source": [
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():       \n",
        "    device = torch.device(\"cuda\")\n",
        "    print(f'There are {torch.cuda.device_count()} GPU(s) available.')\n",
        "    print('Device name:', torch.cuda.get_device_name(0))\n",
        "\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1 GPU(s) available.\n",
            "Device name: Tesla P100-PCIE-16GB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lEPPYHa62JXF"
      },
      "source": [
        "## **Fine-tuning BERT**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bYJRzWI73eBJ"
      },
      "source": [
        "### **Installing the Hugging Face Library**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yxv-EJ2j31Iv"
      },
      "source": [
        "The transformer library of Hugging Face contains PyTorch implementation of state-of-the-art NLP models including BERT (from Google), GPT (from OpenAI) ... and pre-trained model weights."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFiv8WGl4p40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 929
        },
        "outputId": "a25b2b92-535c-496f-eeae-2a769b49befd"
      },
      "source": [
        "!pip install transformers==2.8.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers==2.8.0\n",
            "  Downloading transformers-2.8.0-py3-none-any.whl (563 kB)\n",
            "\u001b[?25l\r\u001b[K     |▋                               | 10 kB 31.5 MB/s eta 0:00:01\r\u001b[K     |█▏                              | 20 kB 32.4 MB/s eta 0:00:01\r\u001b[K     |█▊                              | 30 kB 12.5 MB/s eta 0:00:01\r\u001b[K     |██▎                             | 40 kB 10.1 MB/s eta 0:00:01\r\u001b[K     |███                             | 51 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 61 kB 5.9 MB/s eta 0:00:01\r\u001b[K     |████                            | 71 kB 5.7 MB/s eta 0:00:01\r\u001b[K     |████▋                           | 81 kB 6.4 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 92 kB 6.6 MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 102 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 112 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████                         | 122 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 133 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 143 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 153 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 163 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 174 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 184 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 194 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 204 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 215 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 225 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 235 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 245 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 256 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 266 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 276 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 286 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 296 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 307 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 317 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 327 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 337 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 348 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 358 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 368 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 378 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 389 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 399 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 409 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 419 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 430 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 440 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 450 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 460 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 471 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 481 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 491 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 501 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 512 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 522 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 532 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 542 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 552 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 563 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 563 kB 5.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==2.8.0) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==2.8.0) (3.3.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==2.8.0) (4.62.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==2.8.0) (2019.12.20)\n",
            "Collecting tokenizers==0.5.2\n",
            "  Downloading tokenizers-0.5.2-cp37-cp37m-manylinux1_x86_64.whl (5.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.6 MB 29.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==2.8.0) (1.19.5)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 48.4 MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 77.5 MB/s \n",
            "\u001b[?25hCollecting boto3\n",
            "  Downloading boto3-1.19.7-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 46.7 MB/s \n",
            "\u001b[?25hCollecting botocore<1.23.0,>=1.22.7\n",
            "  Downloading botocore-1.22.7-py3-none-any.whl (8.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.1 MB 73.6 MB/s \n",
            "\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1\n",
            "  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
            "Collecting s3transfer<0.6.0,>=0.5.0\n",
            "  Downloading s3transfer-0.5.0-py3-none-any.whl (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 9.3 MB/s \n",
            "\u001b[?25hCollecting urllib3<1.27,>=1.25.4\n",
            "  Downloading urllib3-1.26.7-py2.py3-none-any.whl (138 kB)\n",
            "\u001b[K     |████████████████████████████████| 138 kB 81.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.23.0,>=1.22.7->boto3->transformers==2.8.0) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.23.0,>=1.22.7->boto3->transformers==2.8.0) (1.15.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.8.0) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.8.0) (2.10)\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 69.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.8.0) (3.0.4)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==2.8.0) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==2.8.0) (1.0.1)\n",
            "Installing collected packages: urllib3, jmespath, botocore, s3transfer, tokenizers, sentencepiece, sacremoses, boto3, transformers\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed boto3-1.19.7 botocore-1.22.7 jmespath-0.10.0 s3transfer-0.5.0 sacremoses-0.0.46 sentencepiece-0.1.96 tokenizers-0.5.2 transformers-2.8.0 urllib3-1.25.11\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "urllib3"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D4sXctSh4sq0"
      },
      "source": [
        "### **Tokenization and Input Formatting**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ygbZpK6qbIYE"
      },
      "source": [
        "Before tokenizing our text, we will perform some slight processing on our text including removing entity mentions (eg. @united) and some special character. The level of processing here is much less than in previous approachs because BERT was trained with the entire sentences."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4L_Rc7l4bgzJ"
      },
      "source": [
        "def text_preprocessing(text):\n",
        "    \"\"\"\n",
        "    - Remove entity mentions (eg. '@united')\n",
        "    - Correct errors (eg. '&amp;' to '&')\n",
        "    @param    text (str): a string to be processed.\n",
        "    @return   text (Str): the processed string.\n",
        "    \"\"\"\n",
        "    # Remove '@name'\n",
        "    text = re.sub(r'(@.*?)[\\s]', ' ', text)\n",
        "\n",
        "    # Replace '&amp;' with '&'\n",
        "    text = re.sub(r'&amp;', '&', text)\n",
        "\n",
        "    # Remove trailing whitespace\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "    return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qyYmHR8McE0r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e959fa47-ecfc-4417-95fa-78ae89e6423b"
      },
      "source": [
        "# Print sentence 0\n",
        "print('Original: ', X[0])\n",
        "print('Processed: ', text_preprocessing(X[0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original:  @united I'm having issues. Yesterday I rebooked for 24 hours after I was supposed to fly, now I can't log on &amp; check in. Can you help?\n",
            "Processed:  I'm having issues. Yesterday I rebooked for 24 hours after I was supposed to fly, now I can't log on & check in. Can you help?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i3acv6s95YYr"
      },
      "source": [
        "### **Creating BERT Tokenizer**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C1fRHtdU5dEn"
      },
      "source": [
        "In order to apply the pre-trained BERT, we must use the tokenizer provided by the library. This is because (1) the model has a specific, fixed vocabulary and (2) the BERT tokenizer has a particular way of handling out-of-vocabulary words.\n",
        "\n",
        "In addition, we are required to add special tokens to the start and end of each sentence, pad & truncate all sentences to a single constant length, and explicitly specify what are padding tokens with the \"attention mask\".\n",
        "\n",
        "The `encode_plus` method of BERT tokenizer will:\n",
        "\n",
        "(1) split our text into tokens,\n",
        "\n",
        "(2) add the special `[CLS]` and `[SEP]` tokens, and\n",
        "\n",
        "(3) convert these tokens into indexes of the tokenizer vocabulary,\n",
        "\n",
        "(4) pad or truncate sentences to max length, and\n",
        "\n",
        "(5) create attention mask.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDAfbCle59tP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "913084ac4d9c48f5910abc1d37e0e4e8",
            "dcf25a1fbdec42b393dfd3c706ae0de4",
            "db6df55602e34660b231f6c4545311e6",
            "21a6d1d3436f474393b5d92a2cf6849d",
            "d146e1c3e5ad47eba853fe3937f6ee4d",
            "a61da213948d434890bd7ee1164d0f6e",
            "f74cfe9248494c46b60efc02480fb327",
            "f945a55dfb4944db8fc65f6b8246b23d",
            "ea6364afffd040ad8b03f544d8cb172d",
            "ea94d92e58ab4ea6a769121b2dec7b6b",
            "885c77acbc804f1da8d979eac5278137"
          ]
        },
        "outputId": "c445b8d6-d3ae-466e-db42-6069865651e4"
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# Load the BERT tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "\n",
        "# Create a function to tokenize a set of texts\n",
        "def preprocessing_for_bert(data):\n",
        "    \"\"\"Perform required preprocessing steps for pretrained BERT.\n",
        "    @param    data (np.array): Array of texts to be processed.\n",
        "    @return   input_ids (torch.Tensor): Tensor of token ids to be fed to a model.\n",
        "    @return   attention_masks (torch.Tensor): Tensor of indices specifying which\n",
        "                  tokens should be attended to by the model.\n",
        "    \"\"\"\n",
        "    # Create empty lists to store outputs\n",
        "    input_ids = []\n",
        "    attention_masks = []\n",
        "\n",
        "    # For every sentence...\n",
        "    for sent in data:\n",
        "        # `encode_plus` will:\n",
        "        #    (1) Tokenize the sentence\n",
        "        #    (2) Add the `[CLS]` and `[SEP]` token to the start and end\n",
        "        #    (3) Truncate/Pad sentence to max length\n",
        "        #    (4) Map tokens to their IDs\n",
        "        #    (5) Create attention mask\n",
        "        #    (6) Return a dictionary of outputs\n",
        "        encoded_sent = tokenizer.encode_plus(\n",
        "            text=text_preprocessing(sent),  # Preprocess sentence\n",
        "            add_special_tokens=True,        # Add `[CLS]` and `[SEP]`\n",
        "            max_length=MAX_LEN,                  # Max length to truncate/pad\n",
        "            pad_to_max_length=True,         # Pad sentence to max length\n",
        "            #return_tensors='pt',           # Return PyTorch tensor\n",
        "            return_attention_mask=True      # Return attention mask\n",
        "            )\n",
        "        \n",
        "        # Add the outputs to the lists\n",
        "        input_ids.append(encoded_sent.get('input_ids'))\n",
        "        attention_masks.append(encoded_sent.get('attention_mask'))\n",
        "\n",
        "    # Convert lists to tensors\n",
        "    input_ids = torch.tensor(input_ids)\n",
        "    attention_masks = torch.tensor(attention_masks)\n",
        "\n",
        "    return input_ids, attention_masks"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "913084ac4d9c48f5910abc1d37e0e4e8",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TNE9oASMZ1bN"
      },
      "source": [
        "Before tokenizing, we need to specify the maximum length of our sentences."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hrbvKGNAlMtt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75cc0269-13fc-49b2-9a24-40123544ea6b"
      },
      "source": [
        "# Concatenate train data and test data\n",
        "all_tweets = np.concatenate([data.tweet.values, test_data.tweet.values])\n",
        "\n",
        "# Encode our concatenated data\n",
        "encoded_tweets = [tokenizer.encode(sent, add_special_tokens=True) for sent in all_tweets]\n",
        "\n",
        "# Find the maximum length\n",
        "max_len = max([len(sent) for sent in encoded_tweets])\n",
        "print('Max length: ', max_len)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max length:  68\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vpdjBB9fmbu2"
      },
      "source": [
        "Now let's tokenize our data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QTlQzTzAfCy7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6fce950b-1dad-482f-e452-36707925883c"
      },
      "source": [
        "# Specify `MAX_LEN`\n",
        "MAX_LEN = 64\n",
        "\n",
        "# Print sentence 0 and its encoded token ids\n",
        "token_ids = list(preprocessing_for_bert([X[0]])[0].squeeze().numpy())\n",
        "print('Original: ', X[0])\n",
        "print('Token IDs: ', token_ids)\n",
        "\n",
        "# Run function `preprocessing_for_bert` on the train set and the validation set\n",
        "print('Tokenizing data...')\n",
        "train_inputs, train_masks = preprocessing_for_bert(X_train)\n",
        "val_inputs, val_masks = preprocessing_for_bert(X_val)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original:  @united I'm having issues. Yesterday I rebooked for 24 hours after I was supposed to fly, now I can't log on &amp; check in. Can you help?\n",
            "Token IDs:  [101, 1045, 1005, 1049, 2383, 3314, 1012, 7483, 1045, 2128, 8654, 2098, 2005, 2484, 2847, 2044, 1045, 2001, 4011, 2000, 4875, 1010, 2085, 1045, 2064, 1005, 1056, 8833, 2006, 1004, 4638, 1999, 1012, 2064, 2017, 2393, 1029, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Tokenizing data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZU8t5VNfvhY"
      },
      "source": [
        "### **Creating PyTorch DataLoader**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aoHdl3gFgMZY"
      },
      "source": [
        "We will create an iterator for our dataset using the torch DataLoader class. This will help save on memory during training and boost the training speed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xHuYEc61gcGL"
      },
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# Convert other data types to torch.Tensor\n",
        "train_labels = torch.tensor(y_train)\n",
        "val_labels = torch.tensor(y_val)\n",
        "\n",
        "# For fine-tuning BERT, the authors recommend a batch size of 16 or 32.\n",
        "batch_size = 32\n",
        "\n",
        "# Create the DataLoader for our training set\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "# Create the DataLoader for our validation set\n",
        "val_data = TensorDataset(val_inputs, val_masks, val_labels)\n",
        "val_sampler = SequentialSampler(val_data)\n",
        "val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSRAga-yj17q"
      },
      "source": [
        "## **Training Our Model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KoOdsDgG8b_Z"
      },
      "source": [
        "### **Creating BertClassifier**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zA_yESCl5nuK"
      },
      "source": [
        "BERT-base consists of 12 transformer layers, each transformer layer takes in a list of token embeddings, and produces the same number of embeddings with the same hidden size (or dimensions) on the output. The output of the final transformer layer of the `[CLS]` token is used as the features of the sequence to feed a classifier.\n",
        "\n",
        "The `transformers` library has the [`BertForSequenceClassification`](https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#bertforsequenceclassification) class which is designed for classification tasks. However, we will create a new class so we can specify our own choice of classifiers.\n",
        "\n",
        "Below we will create a BertClassifier class with a BERT model to extract the last hidden layer of the `[CLS]` token and a single-hidden-layer feed-forward neural network as our classifier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YK41aBFSj5jK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f71eae8-c5f6-4459-e160-bb3834b36b4c"
      },
      "source": [
        "%%time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import BertModel\n",
        "\n",
        "# Create the BertClassfier class\n",
        "class BertClassifier(nn.Module):\n",
        "    \"\"\"Bert Model for Classification Tasks.\n",
        "    \"\"\"\n",
        "    def __init__(self, freeze_bert=False):\n",
        "        \"\"\"\n",
        "        @param    bert: a BertModel object\n",
        "        @param    classifier: a torch.nn.Module classifier\n",
        "        @param    freeze_bert (bool): Set `False` to fine-tune the BERT model\n",
        "        \"\"\"\n",
        "        super(BertClassifier, self).__init__()\n",
        "        # Specify hidden size of BERT, hidden size of our classifier, and number of labels\n",
        "        D_in, H, D_out = 768, 50, 2\n",
        "\n",
        "        # Instantiate BERT model\n",
        "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "        # Instantiate an one-layer feed-forward classifier\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(D_in, H),\n",
        "            nn.ReLU(),\n",
        "            #nn.Dropout(0.5),\n",
        "            nn.Linear(H, D_out)\n",
        "        )\n",
        "\n",
        "        # Freeze the BERT model\n",
        "        if freeze_bert:\n",
        "            for param in self.bert.parameters():\n",
        "                param.requires_grad = False\n",
        "        \n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        \"\"\"\n",
        "        Feed input to BERT and the classifier to compute logits.\n",
        "        @param    input_ids (torch.Tensor): an input tensor with shape (batch_size,\n",
        "                      max_length)\n",
        "        @param    attention_mask (torch.Tensor): a tensor that hold attention mask\n",
        "                      information with shape (batch_size, max_length)\n",
        "        @return   logits (torch.Tensor): an output tensor with shape (batch_size,\n",
        "                      num_labels)\n",
        "        \"\"\"\n",
        "        # Feed input to BERT\n",
        "        outputs = self.bert(input_ids=input_ids,\n",
        "                            attention_mask=attention_mask)\n",
        "        \n",
        "        # Extract the last hidden state of the token `[CLS]` for classification task\n",
        "        last_hidden_state_cls = outputs[0][:, 0, :]\n",
        "\n",
        "        # Feed input to classifier to compute logits\n",
        "        logits = self.classifier(last_hidden_state_cls)\n",
        "\n",
        "        return logits"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 31 µs, sys: 4 µs, total: 35 µs\n",
            "Wall time: 37.2 µs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LwNrCgPh-yR7"
      },
      "source": [
        "### **Optimizer & Learning Rate Scheduler**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V6iOXiN8-8gc"
      },
      "source": [
        "To fine-tune our Bert Classifier, we need to create an optimizer. The authors recommend following hyper-parameters:\n",
        "\n",
        "- Batch size: 16 or 32\n",
        "- Learning rate (Adam): 5e-5, 3e-5 or 2e-5\n",
        "- Number of epochs: 2, 3, 4\n",
        "\n",
        "Huggingface provided the [run_glue.py](https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L109) script, an examples of implementing the `transformers` library. In the script, the AdamW optimizer is used."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JX7su7Q_269U"
      },
      "source": [
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "\n",
        "def initialize_model(epochs=4):\n",
        "    \"\"\"Initialize the Bert Classifier, the optimizer and the learning rate scheduler.\n",
        "    \"\"\"\n",
        "    # Instantiate Bert Classifier\n",
        "    bert_classifier = BertClassifier(freeze_bert=False)\n",
        "\n",
        "    # Tell PyTorch to run the model on GPU\n",
        "    bert_classifier.to(device)\n",
        "\n",
        "    # Create the optimizer\n",
        "    optimizer = AdamW(bert_classifier.parameters(),\n",
        "                      lr=5e-5,    # Default learning rate\n",
        "                      eps=1e-8    # Default epsilon value\n",
        "                      )\n",
        "\n",
        "    # Total number of training steps\n",
        "    total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "    # Set up the learning rate scheduler\n",
        "    scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "                                                num_warmup_steps=0, # Default value\n",
        "                                                num_training_steps=total_steps)\n",
        "    return bert_classifier, optimizer, scheduler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "41DRNjv4B0Ow"
      },
      "source": [
        "### **Creating a Training Loop**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VYU-GQRZG0y8"
      },
      "source": [
        "We will train our Bert Classifier for 4 epochs. In each epoch, we will train our model and evaluate its performance on the validation set. In more details, we will:\n",
        "\n",
        "Training:\n",
        "- Unpacking our data from the dataloader and loading the data onto the GPU\n",
        "- Zeroing out gradients calculated in the previous pass\n",
        "- Performing a forward pass to compute logits and loss\n",
        "- Performing a backward pass to compute gradients (`loss.backward()`)\n",
        "- Clipping the norm of the gradients to 1.0 to prevent \"exploding gradients\"\n",
        "- Updating the model's parameters (`optimizer.step()`)\n",
        "- Updating the learning rate (`scheduler.step()`)\n",
        "\n",
        "Evaluation:\n",
        "- Unpacking our data and load onto the GPU\n",
        "- Forward pass\n",
        "- Computing loss and accuracy rate over the validation set\n",
        "\n",
        "The script below is commented with the details of our training and evaluation loop. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xy4HkhyECibW"
      },
      "source": [
        "import random\n",
        "import time\n",
        "\n",
        "# Specify loss function\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "def set_seed(seed_value=42):\n",
        "    \"\"\"Set seed for reproducibility.\n",
        "    \"\"\"\n",
        "    random.seed(seed_value)\n",
        "    np.random.seed(seed_value)\n",
        "    torch.manual_seed(seed_value)\n",
        "    torch.cuda.manual_seed_all(seed_value)\n",
        "\n",
        "def train(model, train_dataloader, val_dataloader=None, epochs=4, evaluation=False):\n",
        "    \"\"\"Train the BertClassifier model.\n",
        "    \"\"\"\n",
        "    # Start training loop\n",
        "    print(\"Start training...\\n\")\n",
        "    for epoch_i in range(epochs):\n",
        "        # =======================================\n",
        "        #               Training\n",
        "        # =======================================\n",
        "        # Print the header of the result table\n",
        "        print(f\"{'Epoch':^7} | {'Batch':^7} | {'Train Loss':^12} | {'Val Loss':^10} | {'Val Acc':^9} | {'Elapsed':^9}\")\n",
        "        print(\"-\"*70)\n",
        "\n",
        "        # Measure the elapsed time of each epoch\n",
        "        t0_epoch, t0_batch = time.time(), time.time()\n",
        "\n",
        "        # Reset tracking variables at the beginning of each epoch\n",
        "        total_loss, batch_loss, batch_counts = 0, 0, 0\n",
        "\n",
        "        #Tensorboard\n",
        "        tb.add_scalar(\"Total Loss\", total_loss, epoch_i)\n",
        "\n",
        "        # Put the model into the training mode\n",
        "        model.train()\n",
        "\n",
        "        # For each batch of training data...\n",
        "        for step, batch in enumerate(train_dataloader):\n",
        "            batch_counts +=1\n",
        "            # Load batch to GPU\n",
        "            b_input_ids, b_attn_mask, b_labels = tuple(t.to(device) for t in batch)\n",
        "\n",
        "            # Zero out any previously calculated gradients\n",
        "            model.zero_grad()\n",
        "\n",
        "            # Perform a forward pass. This will return logits.\n",
        "            logits = model(b_input_ids, b_attn_mask)\n",
        "\n",
        "            # Compute loss and accumulate the loss values\n",
        "            loss = loss_fn(logits, b_labels)\n",
        "            batch_loss += loss.item()\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            # Perform a backward pass to calculate gradients\n",
        "            loss.backward()\n",
        "\n",
        "            # Clip the norm of the gradients to 1.0 to prevent \"exploding gradients\"\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "            # Update parameters and the learning rate\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "\n",
        "            # Print the loss values and time elapsed for every 20 batches\n",
        "            if (step % 20 == 0 and step != 0) or (step == len(train_dataloader) - 1):\n",
        "                # Calculate time elapsed for 20 batches\n",
        "                time_elapsed = time.time() - t0_batch\n",
        "\n",
        "                # Print training results\n",
        "                print(f\"{epoch_i + 1:^7} | {step:^7} | {batch_loss / batch_counts:^12.6f} | {'-':^10} | {'-':^9} | {time_elapsed:^9.2f}\")\n",
        "\n",
        "                # Reset batch tracking variables\n",
        "                batch_loss, batch_counts = 0, 0\n",
        "                t0_batch = time.time()\n",
        "\n",
        "        # Calculate the average loss over the entire training data\n",
        "        avg_train_loss = total_loss / len(train_dataloader)\n",
        "\n",
        "        print(\"-\"*70)\n",
        "        # =======================================\n",
        "        #               Evaluation\n",
        "        # =======================================\n",
        "        if evaluation == True:\n",
        "            # After the completion of each training epoch, measure the model's performance\n",
        "            # on our validation set.\n",
        "            val_loss, val_accuracy = evaluate(model, val_dataloader)\n",
        "\n",
        "            # Print performance over the entire training data\n",
        "            time_elapsed = time.time() - t0_epoch\n",
        "            \n",
        "            print(f\"{epoch_i + 1:^7} | {'-':^7} | {avg_train_loss:^12.6f} | {val_loss:^10.6f} | {val_accuracy:^9.2f} | {time_elapsed:^9.2f}\")\n",
        "            print(\"-\"*70)\n",
        "        print(\"\\n\")\n",
        "    \n",
        "    print(\"Training complete!\")\n",
        "    tb.close()\n",
        "\n",
        "def evaluate(model, val_dataloader):\n",
        "    \"\"\"After the completion of each training epoch, measure the model's performance\n",
        "    on our validation set.\n",
        "    \"\"\"\n",
        "    # Put the model into the evaluation mode. The dropout layers are disabled during\n",
        "    # the test time.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables\n",
        "    val_accuracy = []\n",
        "    val_loss = []\n",
        "\n",
        "    # For each batch in our validation set...\n",
        "    for batch in val_dataloader:\n",
        "        # Load batch to GPU\n",
        "        b_input_ids, b_attn_mask, b_labels = tuple(t.to(device) for t in batch)\n",
        "\n",
        "        # Compute logits\n",
        "        with torch.no_grad():\n",
        "            logits = model(b_input_ids, b_attn_mask)\n",
        "\n",
        "        # Compute loss\n",
        "        loss = loss_fn(logits, b_labels)\n",
        "        val_loss.append(loss.item())\n",
        "\n",
        "        # Get the predictions\n",
        "        preds = torch.argmax(logits, dim=1).flatten()\n",
        "\n",
        "        # Calculate the accuracy rate\n",
        "        accuracy = (preds == b_labels).cpu().numpy().mean() * 100\n",
        "        val_accuracy.append(accuracy)\n",
        "\n",
        "    # Compute the average accuracy and loss over the validation set.\n",
        "    val_loss = np.mean(val_loss)\n",
        "    val_accuracy = np.mean(val_accuracy)\n",
        "\n",
        "    return val_loss, val_accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BSfTy9LqiFD-"
      },
      "source": [
        "Now, let's start training our BertClassifier!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wfYw7dJ0U0v6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 638,
          "referenced_widgets": [
            "8b5b05fb01644be19618a9f0a8b9a732",
            "2dd84f2cdd4044c48c383266b5f94cf8",
            "e15f3ee1b878428984c744e13fbba70c",
            "ee20693f6f2e479d8f8629ac3fa9f91b",
            "0ea61762657d48e78bc03d080878d86c",
            "fdde4f376cf54e27834be411660ee339",
            "e7369e716d3f44b384145ef9651981dc",
            "84f4244ed40a4467833733f8e11b116d",
            "7fa1ff7fe5e54f3694e7bde8702b98eb",
            "9cb7a283276a401ea0c0ae81974c81e0",
            "4af5d809ad4e4904aab501577cc046ff",
            "367b641da98f47e2b79f186af9a56cf1",
            "68c1147d196a4e1aa8899bf43fcb096f",
            "35ef0385b1254005a745fdbb2447d6dd",
            "3ea1d598c5b34a2db818084f25b1f18c",
            "861a0eb9b8104131aa19789d87495d75",
            "a4d2d6abc3cf4900b2f16fba490460ab",
            "9da3848c6a6443c3b4fe85e789bab750",
            "1ec5430d630b4900a37ed8f98f4213fa",
            "9df819fd50df43279a005f56e25ef58b",
            "6c23819ebda540b8a17e551a29d0e9d6",
            "1ec0f63e1b304f9290390917b9b7ea3b"
          ]
        },
        "outputId": "238225b4-006e-4e24-caaf-a56f14b85a1c"
      },
      "source": [
        "set_seed(42)    # Set seed for reproducibility\n",
        "bert_classifier, optimizer, scheduler = initialize_model(epochs=2)\n",
        "train(bert_classifier, train_dataloader, val_dataloader, epochs=2, evaluation=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8b5b05fb01644be19618a9f0a8b9a732",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/433 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "367b641da98f47e2b79f186af9a56cf1",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start training...\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:155: UserWarning: This overload of add_ is deprecated:\n",
            "\tadd_(Number alpha, Tensor other)\n",
            "Consider using one of the following signatures instead:\n",
            "\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:1025.)\n",
            "  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   1    |   20    |   0.658668   |     -      |     -     |   4.47   \n",
            "   1    |   40    |   0.558918   |     -      |     -     |   4.11   \n",
            "   1    |   60    |   0.541147   |     -      |     -     |   4.12   \n",
            "   1    |   80    |   0.496406   |     -      |     -     |   4.12   \n",
            "   1    |   95    |   0.443480   |     -      |     -     |   3.03   \n",
            "----------------------------------------------------------------------\n",
            "   1    |    -    |   0.545975   |  0.430542  |   80.68   |   20.51  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "   2    |   20    |   0.334403   |     -      |     -     |   4.35   \n",
            "   2    |   40    |   0.306869   |     -      |     -     |   4.11   \n",
            "   2    |   60    |   0.302477   |     -      |     -     |   4.13   \n",
            "   2    |   80    |   0.274638   |     -      |     -     |   4.13   \n",
            "   2    |   95    |   0.270355   |     -      |     -     |   3.04   \n",
            "----------------------------------------------------------------------\n",
            "   2    |    -    |   0.299557   |  0.423068  |   80.85   |   20.40  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            "Training complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dXQDARwiZMTE",
        "outputId": "6d238145-96ba-4e00-a8d4-bef6ec12f4f7"
      },
      "source": [
        "!tensorboard --logdir runs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2021-10-30 05:46:36.088819: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-10-30 05:46:36.297241: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-10-30 05:46:36.297778: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "\n",
            "NOTE: Using experimental fast data loading logic. To disable, pass\n",
            "    \"--load_fast=false\" and report issues on GitHub. More details:\n",
            "    https://github.com/tensorflow/tensorboard/issues/4784\n",
            "\n",
            "Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all\n",
            "TensorBoard 2.6.0 at http://localhost:6006/ (Press CTRL+C to quit)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D5ostg9kPlra"
      },
      "source": [
        "### **Evaluation on Validation Set**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fIlSTDA7Z9DF"
      },
      "source": [
        "The prediction step is similar to the evaluation step that we did in the training loop, but simpler. We will perform a forward pass to compute logits and apply softmax to calculate probabilities."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V5_w4erqGzpe"
      },
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "def bert_predict(model, test_dataloader):\n",
        "    \"\"\"Perform a forward pass on the trained BERT model to predict probabilities\n",
        "    on the test set.\n",
        "    \"\"\"\n",
        "    # Put the model into the evaluation mode. The dropout layers are disabled during\n",
        "    # the test time.\n",
        "    model.eval()\n",
        "\n",
        "    all_logits = []\n",
        "\n",
        "    # For each batch in our test set...\n",
        "    for batch in test_dataloader:\n",
        "        # Load batch to GPU\n",
        "        b_input_ids, b_attn_mask = tuple(t.to(device) for t in batch)[:2]\n",
        "\n",
        "        # Compute logits\n",
        "        with torch.no_grad():\n",
        "            logits = model(b_input_ids, b_attn_mask)\n",
        "        all_logits.append(logits)\n",
        "    \n",
        "    # Concatenate logits from each batch\n",
        "    all_logits = torch.cat(all_logits, dim=0)\n",
        "\n",
        "    # Apply softmax to calculate probabilities\n",
        "    probs = F.softmax(all_logits, dim=1).cpu().numpy()\n",
        "\n",
        "    return probs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wkw5DOSaw_oA"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, roc_curve, auc\n",
        "\n",
        "def evaluate_roc(probs, y_true):\n",
        "    \"\"\"\n",
        "    - Print AUC and accuracy on the test set\n",
        "    - Plot ROC\n",
        "    @params    probs (np.array): an array of predicted probabilities with shape (len(y_true), 2)\n",
        "    @params    y_true (np.array): an array of the true values with shape (len(y_true),)\n",
        "    \"\"\"\n",
        "    preds = probs[:, 1]\n",
        "    fpr, tpr, threshold = roc_curve(y_true, preds)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    print(f'AUC: {roc_auc:.4f}')\n",
        "       \n",
        "    # Get accuracy over the test set\n",
        "    y_pred = np.where(preds >= 0.5, 1, 0)\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    print(f'Accuracy: {accuracy*100:.2f}%')\n",
        "    \n",
        "    # Plot ROC AUC\n",
        "    plt.title('Receiver Operating Characteristic')\n",
        "    plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "    plt.legend(loc = 'lower right')\n",
        "    plt.plot([0, 1], [0, 1],'r--')\n",
        "    plt.xlim([0, 1])\n",
        "    plt.ylim([0, 1])\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.show()"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kcmj5s0eRMUh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "outputId": "eb37bde7-4231-46c9-a576-4a799f5f89a7"
      },
      "source": [
        "# Compute predicted probabilities on the test set\n",
        "probs = bert_predict(bert_classifier, val_dataloader)\n",
        "\n",
        "# Evaluate the Bert classifier\n",
        "evaluate_roc(probs, y_val)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUC: 0.8993\n",
            "Accuracy: 80.88%\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XekOuD6KbS2Q"
      },
      "source": [
        "The Bert Classifer achieves 0.90 AUC score and 82.65% accuracy rate on the validation set. This result is 10 points better than the baseline method. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G5DW6grRmfT-"
      },
      "source": [
        "### **Training our Model on the Entire Training Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JkMK5VqJJvSO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce507ebd-87c9-4eac-97c7-370393c58e3e"
      },
      "source": [
        "# Concatenate the train set and the validation set\n",
        "full_train_data = torch.utils.data.ConcatDataset([train_data, val_data])\n",
        "full_train_sampler = RandomSampler(full_train_data)\n",
        "full_train_dataloader = DataLoader(full_train_data, sampler=full_train_sampler, batch_size=32)\n",
        "\n",
        "# Train the Bert Classifier on the entire training data\n",
        "set_seed(42)\n",
        "bert_classifier, optimizer, scheduler = initialize_model(epochs=2)\n",
        "train(bert_classifier, full_train_dataloader, epochs=2)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start training...\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "   1    |   20    |   0.675866   |     -      |     -     |   4.34   \n",
            "   1    |   40    |   0.569736   |     -      |     -     |   4.14   \n",
            "   1    |   60    |   0.514143   |     -      |     -     |   4.12   \n",
            "   1    |   80    |   0.463472   |     -      |     -     |   4.13   \n",
            "   1    |   100   |   0.465977   |     -      |     -     |   4.11   \n",
            "   1    |   106   |   0.409391   |     -      |     -     |   1.11   \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "   2    |   20    |   0.335200   |     -      |     -     |   4.34   \n",
            "   2    |   40    |   0.298954   |     -      |     -     |   4.12   \n",
            "   2    |   60    |   0.289389   |     -      |     -     |   4.11   \n",
            "   2    |   80    |   0.314846   |     -      |     -     |   4.14   \n",
            "   2    |   100   |   0.270398   |     -      |     -     |   4.12   \n",
            "   2    |   106   |   0.315642   |     -      |     -     |   1.12   \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            "Training complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q89oT0n3N0m6"
      },
      "source": [
        "### **Predictions on Test Set**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sqk_CPwjN_W0"
      },
      "source": [
        "### **Data Preparation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MaPBmrFBO-uQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "outputId": "ca7dc7c2-d0a6-454d-c10c-df0b1016cfc3"
      },
      "source": [
        "test_data.sample(5)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>471</th>\n",
              "      <td>18654</td>\n",
              "      <td>Friends and family: Never fly @JetBlue.  Absol...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1971</th>\n",
              "      <td>76265</td>\n",
              "      <td>@DeltaAssist @rogerioad I never have had a pro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>672</td>\n",
              "      <td>First flight in weeks. Counting on you @Americ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2702</th>\n",
              "      <td>103263</td>\n",
              "      <td>\"@USAirways: You know that we can__t stay no m...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>135</th>\n",
              "      <td>5137</td>\n",
              "      <td>@southwestair Here at SA Airport watching the ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          id                                              tweet\n",
              "471    18654  Friends and family: Never fly @JetBlue.  Absol...\n",
              "1971   76265  @DeltaAssist @rogerioad I never have had a pro...\n",
              "23       672  First flight in weeks. Counting on you @Americ...\n",
              "2702  103263  \"@USAirways: You know that we can__t stay no m...\n",
              "135     5137  @southwestair Here at SA Airport watching the ..."
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AzCpJBgWZYR_"
      },
      "source": [
        "Before making predictions on the test set, we need to redo processing and encoding steps done on the training data. Fortunately, we have written the `preprocessing_for_bert` function to do that for us."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56QTDchdOHBL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46e8a694-54f6-4304-b3ec-99053d039e03"
      },
      "source": [
        "# Run `preprocessing_for_bert` on the test set\n",
        "print('Tokenizing data...')\n",
        "test_inputs, test_masks = preprocessing_for_bert(test_data.tweet)\n",
        "\n",
        "# Create the DataLoader for our test set\n",
        "test_dataset = TensorDataset(test_inputs, test_masks)\n",
        "test_sampler = SequentialSampler(test_dataset)\n",
        "test_dataloader = DataLoader(test_dataset, sampler=test_sampler, batch_size=32)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenizing data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tGx8h7yXRkfI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a441388-f61b-429a-e2f8-b86858071d54"
      },
      "source": [
        "# Compute predicted probabilities on the test set\n",
        "probs = bert_predict(bert_classifier, test_dataloader)\n",
        "\n",
        "# Get predictions from the probabilities\n",
        "threshold = 0.9\n",
        "preds = np.where(probs[:, 1] > threshold, 1, 0)\n",
        "\n",
        "# Number of tweets predicted non-negative\n",
        "print(\"Number of tweets predicted non-negative: \", preds.sum())"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of tweets predicted non-negative:  406\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0GMqDdsScTQb"
      },
      "source": [
        "Now we will examine 20 random tweets from our predictions. 17 of them are correct, showing that the BERT Classifier acquires about 0.85 precision rate."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aCTfCTRfWZhe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f3447e5-c241-40c9-f42d-818b1d0c55c4"
      },
      "source": [
        "output = test_data[preds==1]\n",
        "list(output.sample(20).tweet)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Stories like this are why I__m glad to fly @SouthwestAir RT @ZacMoffatt: Why Airlines Want to Make You Suffer http://t.co/Mu7FRW2CV5',\n",
              " \"I've never seen the @AmericanAir club so packed at #lax. Blame it on #rainpocalypse  Daniel @ the bar is the best though. #travel #mydayinla\",\n",
              " '@SirScoots @AmericanAir oh wat, when do you leave sna?',\n",
              " \"@NYCAviation @JetBlue I like it!  Can't wait to see it on the @BostonLogan runways and Tarmac.\",\n",
              " '@JasonandAxel @united awwww poor Axel!! _',\n",
              " '@richeisen @united Rich, fly @AmericanAir zero problems &amp; I fly weekly! #firstworldproblems',\n",
              " '@united @IvanAlberCPP lol this twitter page is so fucking useful.',\n",
              " \"Booked 20 flights in the last 20 mins. Lol. Black Friday ain't so bad. @VirginAmerica\",\n",
              " \"@SandiHLogan @bk8logan @AmericanAir  couldn't be worse than United who live up to their .always late rep every time.\",\n",
              " '@united oh man switched things up today and flew @delta got a pillow and a blanket on a RJ. You guys have some catch up to do.',\n",
              " 'Huge! RT @nomadicmatt: Holy hell!! @JetBlue offers free wifi on their flights!! I definitely booking more flights with Jetblue now!',\n",
              " '@united ;-) help spread awareness for how bad bombs r. #GamerGate #notyourshield @TheQuinnspiracy http://t.co/j2pIiXzBem',\n",
              " '@SouthwestAir my mother and I are going to miss connection from chi to sfo at 710pm tonight. Is there another plane to get us there tonight?',\n",
              " \"@united please don't delay this flight! I really want to make it to my honeymoon!\",\n",
              " 'Dear @VirginAmerica - you know i love you...but when there is a close #FiestaBowl going on can we please delay the music video? cc @DSBerk',\n",
              " 'Arrived in new orleans just in time for SC14 after having problems with my flight. Thanks to @AlaskaAir and especially Oksana.',\n",
              " \"maybe I'm late to the game, but so glad that @SouthwestAir now interfaces with @passbook_ios! now if all the other airlines would play along\",\n",
              " \"@DeltaAssist When will my rollover #MQMs from last year show up on my  #2016medalliontracker as #MQMs?  I hope they're not #lost!\",\n",
              " \"Let's do this @jetblue !!!! Can't wait to get home http://t.co/z3QTEqGtjA\",\n",
              " \"@JLJeffLewis @AmericanAir you're too funny Jeff and can't wait for your show to come back!!....without Gage\"]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gl_ymkJCH3sn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04d32128-f5c2-4a35-a21f-b19fd339887a"
      },
      "source": [
        "if (probs[0][0] > 0.5):\n",
        "  print(\"positive\")"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "positive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CA9hnj3eI90x"
      },
      "source": [
        "text = '@NYCAviation @JetBlue I like it!  Cant wait to see it on the @BostonLogan runways and Tarmac.'"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WhJo3IQVJKTo"
      },
      "source": [
        "text_input, text_mask = preprocessing_for_bert(text)\n",
        "\n",
        "# Create the DataLoader for our test set\n",
        "text_data = TensorDataset(text_input, text_mask)\n",
        "text_sampler = SequentialSampler(text_data)\n",
        "text_dataloader = DataLoader(text_data, sampler=text_sampler, batch_size=32)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ikjyufzBJeUS"
      },
      "source": [
        "# Compute predicted probabilities on the test set\n",
        "probability = bert_predict(bert_classifier, text_dataloader)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ujE3crTZJiTD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97688005-5878-4a7f-e2b8-d561412bb3e6"
      },
      "source": [
        "if (probs[0][0] > 0.9):\n",
        "  print(\"positive\")\n",
        "else:\n",
        "  print(\"negative\")"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "positive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kdn7IFauJ3lR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b201286-5cf5-4a92-c641-59dba7d883a2"
      },
      "source": [
        "probs[0]"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.9517073 , 0.04829273], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zdmCsyRS-ytQ"
      },
      "source": [
        "# **Gradio**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-ng8d7--z3i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2caaf03e-ed90-42f8-8eff-8d39c47f3991"
      },
      "source": [
        "!pip install -q gradio"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 2.0 MB 5.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 206 kB 51.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.9 MB 58.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 961 kB 55.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 63 kB 2.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.5 MB 18.3 MB/s \n",
            "\u001b[?25h  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for flask-cachebuster (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aDvyftZm_F1d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 571
        },
        "outputId": "2fa522da-7377-4362-ea0e-f9b4d9003c50"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "# from urllib.request import urlretrieve\n",
        "import gradio as gr\n",
        "\n",
        "def sentiment_analysis(text):\n",
        "    text_input, text_mask = preprocessing_for_bert(text)\n",
        "\n",
        "    # Create the DataLoader for our test set\n",
        "    text_data = TensorDataset(text_input, text_mask)\n",
        "    text_sampler = SequentialSampler(text_data)\n",
        "    text_dataloader = DataLoader(text_data, sampler=text_sampler, batch_size=32)\n",
        "\n",
        "    # Compute predicted probabilities on the test set\n",
        "    probability = bert_predict(bert_classifier, text_dataloader)\n",
        "\n",
        "    if (probs[0][0] > 0.9):\n",
        "      return \"positive\"\n",
        "    else:\n",
        "      return \"negative\"\n",
        "\n",
        "    return pred_test\n",
        "\n",
        "gr.Interface(fn=sentiment_analysis, \n",
        "             inputs=\"textbox\", \n",
        "             outputs='textbox').launch(share=True);"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set `debug=True` in `launch()`\n",
            "This share link will expire in 72 hours. If you need a permanent link, visit: https://gradio.app/introducing-hosted\n",
            "Running on External URL: https://39652.gradio.app\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"900\"\n",
              "            height=\"500\"\n",
              "            src=\"https://39652.gradio.app\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "        ></iframe>\n",
              "        "
            ],
            "text/plain": [
              "<IPython.lib.display.IFrame at 0x7efe49ab4250>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UMg9ZUvocF6U"
      },
      "source": [
        "By adding a simple one-hidden-layer neural network classifier on top of BERT and fine-tuning BERT, we can achieve near state-of-the-art performance, which is 10 points better than the baseline method.\n",
        "\n",
        "In addition, although BERT is very large, complicated, and have millions of parameters, we only need to fine-tune it in only 2-4 epochs. That result can be achieved because BERT was trained on the huge amount and already encode a lot of information about our language. An impresive performance achieved in a short amount of time, with a small amount of data has shown why BERT is one of the most powerful NLP models available currently. "
      ]
    }
  ]
}